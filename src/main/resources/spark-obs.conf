fs.s3a.access.key=SFJSK2MNTKT9WJJUWXGE
fs.s3a.secret.key=Teq8D2QdQH8aFeMpQwApMl8lGI3xYq7AAs2Lr3nW
fs.s3a.endpoint=obs.cn-north-1.myhuaweicloud.com
fs.obs.access.key=SFJSK2MNTKT9WJJUWXGE
fs.obs.secret.key=Teq8D2QdQH8aFeMpQwApMl8lGI3xYq7AAs2Lr3nW
fs.obs.endpoint=obs.cn-north-1.myhuaweicloud.com
spark.hadoop.fs.s3a.access.key=SFJSK2MNTKT9WJJUWXGE
spark.hadoop.fs.s3a.secret.key=Teq8D2QdQH8aFeMpQwApMl8lGI3xYq7AAs2Lr3nW
spark.hadoop.fs.s3a.endpoint=obs.cn-north-1.myhuaweicloud.com
spark.hadoop.fs.obs.access.key=SFJSK2MNTKT9WJJUWXGE
spark.hadoop.fs.obs.secret.key=Teq8D2QdQH8aFeMpQwApMl8lGI3xYq7AAs2Lr3nW
spark.hadoop.fs.obs.endpoint=obs.cn-north-1.myhuaweicloud.com
fs.AbstractFileSystem.s3a.impl=org.apache.hadoop.fs.obs.OBS
fs.AbstractFileSystem.obs.impl=org.apache.hadoop.fs.obs.OBS
fs.obs.impl=org.apache.hadoop.fs.obs.OBSFileSystem
fs.s3a.impl=org.apache.hadoop.fs.obs.OBSFileSystem
spark.hadoop.fs.AbstractFileSystem.s3a.impl=org.apache.hadoop.fs.obs.OBS
spark.hadoop.fs.AbstractFileSystem.obs.impl=org.apache.hadoop.fs.obs.OBS
spark.hadoop.fs.obs.impl=org.apache.hadoop.fs.obs.OBSFileSystem
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.obs.OBSFileSystem

spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3a org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory
spark.hadoop.mapreduce.outputcommitter.factory.scheme.s3n org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory
spark.hadoop.mapreduce.outputcommitter.factory.scheme.obs org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory
##下列配置是将来在实际环境上且对接obs存储的时候才使用的
#warehouse在obs路径，注意修改为实际bucket
spark.sql.warehouse.dir                obs://vgic-datalake/carbon/sparksql-warehouse

#mrs集群中hive metastore thrift地址，注意修改为实际ip
hive.metastore.uris                    thrift://192.168.100.204:9083

